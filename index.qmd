---
title: Kaggle R Comp Template
abstract: >-

authors: 
  - name: Guillaume Gilles
    orcid: 0009-0000-7940-9359
    email: guillaumegilles@me.com
bibliography: assets/references.bib
citation-location: margin
image: assets/header.png
date: 2024-09-19
date-modified: 2024-11-21
categories:
  - Kaggle
  - Machine Learning
  - R
format: 
  html: 
    toc: true
    toc-depth: 3
draft: true
---

## Create a virtual environment: [[poetry]]
## EDA
### Collecting Data

```{R}
library(tidyverse)
library(lubridate)

url <- "https://data.cityofchicago.org/api/views/5neh-572f/rows.csv?accessType=DOWNLOAD&bom=true&format=true"

all_stations <- 
  # Step 1: Read in the data.
  read_csv(url) %>% 
  # Step 2: filter columns and rename stationname
  dplyr::select(station = stationname, date, rides) %>% 
  # Step 3: Convert the character date field to a date encoding.
  # Also, put the data in units of 1K rides
  mutate(date = mdy(date), rides = rides / 1000) %>% 
  # Step 4: Summarize the multiple records using the maximum.
  group_by(date, station) %>% 
  summarize(rides = max(rides), .groups = "drop")
```

### Data Analysis
  - preprocessing
  - encoding bool + string
  - normalization / standardization
  - feature engineer
## Modeling
  - machine learning
  - deep learning

#### importer un jeu données avec R

![[r.read-table#syntaxe]]

## Erreurs à éviter

- séparateur de colonnes mal spécifié ;
- séparateur décimal mal spécifié (les variable risquent d’être considérées comme qualitatives) ;
- tabulations qui remplace un blanc ;
- nom de ligne ou de colonne comprenant une apostrophe ;
- encodage du fichier de donnée lorsq’il y a des caractères accentués ;
- problème dans un guillement non fermé.

## Références

- @hussonPourStatistiqueScience2018
- @MachineLearningPython

```{r}
# Quarto R setup chunck by Julia Silge (https://www.youtube.com/watch?v=5BojM5EciPs)
# library(tidyverse)
# library(tidymodels)
# library(ranger)

# library(knitr)
# knitr::opts_chunk$set(
#     cache = TRUE,
#     cache.lazy = FALSE,
#     warning = FALSE,
#     message =  FALSE,
#     echo = TRUE,
#     dpi = 180,
#     fig.width = 8,
#     fig.height = 5
# )

# theme_set(theme_minimal())
# update_geom_defaults("rect", list(fill = "midnightblue", alpha = 0.8))
# update_geom_defaults("line", list(color = "midnightblue", alpha = 0.8))
# update_geom_defaults("point", list(color = "midnightblue", alpha = 0.8))
# ```

# ```{r}
# valid <- read_csv("/kaggle/input/child-mind-institute-problematic-internet-use/test.csv")
# train <- read_csv("/kaggle/input/child-mind-institute-problematic-internet-use/train.csv")
# ```

# ```{r}
# train |>
#   count(sii)
# ```

# ```{r}
# sum(is.na(train$sii))
# ```
# ```{r}
# # What are different number of features in train and test set?
# # there 23 different feature:
# #   1. 22 Parent-Child Internet Addiction Test (PCIAT) features
# #   2. the target, sii

# # removing PCIAT features
# train_less_pciat <- glimpse(train |>
#   select(!starts_with('PCIAT')))
# ```

# ```{r}
# # Vector of categorial features
# categorial_features <- c("FGC-FGC_CU_Zone", "FGC-FGC_GSND_Zone", "FGC-FGC_GSD_Zone",
#                          "FGC-FGC_PU_Zone", "FGC-FGC_SRL_Zone", "FGC-FGC_SRR_Zone",
#                          "FGC-FGC_TL_Zone", "BIA-BIA_Activity_Level_num", "BIA-BIA_Frame_num",
#                          "PreInt_EduHx-computerinternet_hoursday", "sii")
# ```


# ```{r}
# # Converting features into factor
# train_factored <- train_less_pciat |>
#   mutate_if(is.character, as.factor) |>
#   mutate(across(categorial_features, as.factor))
# glimpse(train_factored)
# train <- train_factored
# ```


# ```{r}
# train_factored %>%
#   ggplot(aes(sii, "SDS-SDS_Total_T")) +
#   geom_col()
# ```

# ### Data visualization
# #### Demographics
# ##### Sexe
# ##### Age distribution
# #### Target distribution

# ## Baseline

# ```{r}
# train_split <- train %>%
#   drop_na(sii) %>%
#   initial_split()

# training_data <- training(train_split)
# testing_data <- testing(train_split)
# ```

# ```{r}
# # Define the random forest model
# rf_model <- rand_forest(trees = 100, mtry = 3, min_n = 5) %>%
#   set_engine("ranger") %>%
#   set_mode("classification")  # Change to "regression" if predicting continuous values
# ```

# ```{r}
# # Create a recipe
# rf_recipe <- recipe(sii ~ ., data = training_data) %>%
#   step_impute_mean(all_numeric_predictors()) %>%       # Mean Imputation
#   step_impute_mode(all_nominal_predictors()) %>%       # Mode Imputation
#   step_normalize(all_numeric_predictors())             # Normalize numeric predictors if needed 
# ```

# ```{r}
# # Create a workflow
# rf_workflow <- workflow() %>%
#   add_recipe(rf_recipe) %>%
#   add_model(rf_model)
# ```

# ```{r}
# # Fit the model
# rf_fit <- rf_workflow %>%
#   fit(data = training_data)
# ```

# ```{r}
# # Make predictions
# predictions <- rf_fit %>%
#   predict(new_data = testing_data) %>%
#   bind_cols(testing_data)
# ```

# ```{r}
# # Evaluate performance
# metrics <- metrics(predictions, truth = sii, estimate = .pred_class)  # Change .pred_class to the appropriate column name
# print(metrics)
# ```

# ```{r}
# qwk <- kap(predictions, truth = sii, estimate = .pred_class, weighting = "quadratic")
# qwk
# ```

# ## Submission

# ```{r}
# ## Submission
# # need to bind valid$id + prediction on valid_set

# # Preparing valid dataset for prediction

# valid <- read_csv("/kaggle/input/child-mind-institute-problematic-internet-use/test.csv")

# valid_less_pciat <- glimpse(valid |>
#   select(!starts_with('PCIAT')))

# categorial_features <- c("FGC-FGC_CU_Zone", "FGC-FGC_GSND_Zone", "FGC-FGC_GSD_Zone",
#                          "FGC-FGC_PU_Zone", "FGC-FGC_SRL_Zone", "FGC-FGC_SRR_Zone",
#                          "FGC-FGC_TL_Zone", "BIA-BIA_Activity_Level_num", "BIA-BIA_Frame_num",
#                          "PreInt_EduHx-computerinternet_hoursday")

# valid <- valid_less_pciat |>
#   mutate_if(is.character, as.factor) |>
#   mutate(across(categorial_features, as.factor))

# # Creating a submission.csv

# submission <- rf_fit %>%
#   predict(new_data = valid) %>%
#   bind_cols(valid) %>%
#   select(id, .pred_class)  # Replace .pred_class with the name of the prediction column if needed

# # Rename the prediction column to match the competition's requirements
# colnames(submission) <- c("id", "sii")

# write_csv(submission, "submission.csv")

# # 0.225 = top 95%
# ```

# ## References

# ::: {ref}

# :::
